_BASE_: Base.yaml
MODEL:
  WEIGHTS: 'pretrained/m2f_panseg/model_final_94dc52.pth'
  META_ARCHITECTURE: "BoxVIS_VideoMaskFormer"
  MASK_FORMER:
      TRANSFORMER_DECODER_NAME: "VideoMultiScaleMaskedTransformerDecoderUni"
      CLASS_WEIGHT: 5.0
      MASK_WEIGHT: 3.0
      DICE_WEIGHT: 3.0
      REID_WEIGHT: 0.5
DATASETS:
  DATASET_RATIO: 
  - 1.0
  - 1.0
  TRAIN: 
  - "coco_panoptic_train"
  - "sa_1b_train_250k_1"
  TEST: ("coco_2017_val_panoptic_with_sem_seg", )
INPUT:
  SAMPLING_FRAME_NUM: 1
  SAMPLING_FRAME_RANGE: 10
  MIN_SIZE_TEST: 1024
SOLVER:
  IMS_PER_BATCH: 2
  STEPS: (160000,)
  MAX_ITER: 180000  # 2x for bs=16
OUTPUT_DIR: output/univs_r50_bs8_sa1b+coco_test/