_BASE_: univs_R50_bs8_coco+sa1b.yaml
MODEL:
  WEIGHTS: 'pretrained/m2f_panseg/model_final_94dc52.pkl'
  META_ARCHITECTURE: "BoxVIS_VideoMaskFormer"
  SEM_SEG_HEAD:
    NUM_CLASSES: 40
  MASK_FORMER:
      NUM_OBJECT_QUERIES: 200
      CLASS_WEIGHT: 5.0
      MASK_WEIGHT: 3.0
      DICE_WEIGHT: 3.0
      REID_WEIGHT: 0.25
      TEST:
        SEMANTIC_ON: False
        INSTANCE_ON: False
        PANOPTIC_ON: True
        OVERLAP_THRESHOLD: 0.8
        OBJECT_MASK_THRESHOLD: 0.05
        STABILITY_SCORE_THRESH: 0.
  BoxVIS:
    TEST:
      ZERO_SHOT_INFERENCE: False
      TRACKER_TYPE: 'minvis'
      APPLY_CLS_THRES: 0.05
DATASETS:
  DATASET_RATIO:
    # - 0.5  # coco 118k
    - 0.5  # ovis 42k
    - 1.0  # ytvis21 90k
    - 1.0  # vipseg 85k
  TRAIN:
    # - "coco_panoptic_train"    # 117k  Note: max(H, W) >= 480
    - "ovis_train"             # 35k  (551 videos)
    - "ytvis_2021_train"       # 90k  (2679 videos)
    - "vipseg_panoptic_train"  # 85k
  TEST: ("ytvis_2021_dev", )
INPUT:
  SAMPLING_FRAME_NUM: 3
  SAMPLING_FRAME_RANGE: 10
  MIN_SIZE_TEST: 480
SOLVER:
  IMS_PER_BATCH: 2
  STEPS: (80000, 90000)
  MAX_ITER: 100000  # 0.5x for bs=8
TEST:
  DETECTIONS_PER_IMAGE: 35
OUTPUT_DIR: output/univs_R50_bs16_f3_vis+vps_LSGaug_200queries_dataloader_iter_100k/